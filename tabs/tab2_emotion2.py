import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from components.wordcloud_plot import generate_wordcloud_image
from components.treemap_plot import prepare_log_nom_treemap_data, show_treemap
from utils.text_cleaner import STOPWORDS, extract_context, normalize_texts
from collections import Counter
from konlpy.tag import Okt
from sklearn.feature_extraction.text import CountVectorizer

POS_TARGETS = ['ì¢‹', 'ë§Œì¡±', 'í›Œë¥­', 'ê¹”ë”', 'í¸í•˜', 'ë¹ ë¥´', 'ì˜ˆì˜', 'ê°ë™', 'ì‹ ë‚˜', 'í–‰ë³µ', 'ì‚¬ë‘', 'ìœ ìš©', 'ê¸°ë¶„ì¢‹', 'ì¬ë°Œ', 'ì¦ê²', 'ê³ ê¸‰', 'ì„¸ë ¨', 'ì¹œì ˆ', 'ì •í™•', 'íŠ¼íŠ¼']
NEG_TARGETS = ['ë³„ë¡œ', 'ë¶ˆí¸', 'ê³ ì¥', 'ëŠë¦¬', 'ëŠë¦¼', 'ì‹¤ë§', 'ì§œì¦', 'í™”ë‚¨', 'ë¶ˆë§Œ', 'ì•„ì‰¬', 'ë¶€ì¡±', 'ë§í•¨', 'ë¶ˆì¾Œ', 'ì§€ë£¨', 'ë¶ˆì¹œì ˆ', 'ë³µì¡', 'í—·ê°ˆë¦¼', 'ì•½í•¨', 'ë¬´ê±°ì›€', 'ë¶ˆëŸ‰']


def render(tag_grouped_dfs):
    st.subheader("ì œí’ˆ ì¢…ë¥˜ë³„ ë¦¬ë·° ë¶„ì„")

    if not tag_grouped_dfs:
        st.warning("âš ï¸ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì œí’ˆ ë¶„ë¥˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    product_options = list(tag_grouped_dfs.keys())
    if not product_options:
        st.warning("âš ï¸ ì„ íƒí•  ìˆ˜ ìˆëŠ” ì œí’ˆ ì¢…ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    selected = st.selectbox("ì œí’ˆ ì¢…ë¥˜ ì„ íƒ", product_options)

    if not selected or selected not in tag_grouped_dfs:
        st.warning("âš ï¸ ìœ íš¨í•œ ì œí’ˆì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    df = tag_grouped_dfs[selected]
    if df is None or df.empty:
        st.warning("âš ï¸ í•´ë‹¹ ì œí’ˆì˜ ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    if 'ë¦¬ë·°ì‘ì„±ì¼' not in df.columns:
        st.warning("âš ï¸ 'ë¦¬ë·°ì‘ì„±ì¼' ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    okt = Okt()
    df = df.copy()
    df['ë¦¬ë·°ì‘ì„±ì¼'] = pd.to_datetime(df['ë¦¬ë·°ì‘ì„±ì¼'], format='%Y%m%d', errors='coerce')
    df = df.dropna(subset=['ë¦¬ë·°ì‘ì„±ì¼'])
    df['ì›”'] = df['ë¦¬ë·°ì‘ì„±ì¼'].dt.to_period('M')

    months = sorted(df['ì›”'].unique())
    if len(months) >= 2:
        date_range = [p.to_timestamp() for p in months]
        start_date = date_range[0].date()
        end_date = date_range[-1].date()
        selected_range = st.slider(
            "ê¸°ê°„ ì„ íƒ (ì›” ë‹¨ìœ„)",
            min_value=start_date,
            max_value=end_date,
            value=(start_date, end_date),
            format="YYYY-MM"
        )
        df = df[(df['ë¦¬ë·°ì‘ì„±ì¼'] >= pd.to_datetime(selected_range[0])) &
                (df['ë¦¬ë·°ì‘ì„±ì¼'] <= pd.to_datetime(selected_range[1]) + pd.offsets.MonthEnd(0))]

    df['ì›”'] = df['ë¦¬ë·°ì‘ì„±ì¼'].dt.to_period('M').astype(str)
    df['ë¦¬ë·°ê¸¸ì´'] = df['ë¦¬ë·° ë‚´ìš©'].astype(str).apply(len)

    monthly_summary = df.groupby('ì›”').agg({'ë¦¬ë·° ë‚´ìš©': 'count', 'ë³„ì ': 'mean'}).rename(columns={'ë¦¬ë·° ë‚´ìš©': 'ë¦¬ë·° ìˆ˜'}).reset_index()
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    step = 1 if len(monthly_summary) <= 12 else 2 if len(monthly_summary) <= 24 else 4
    ticks = monthly_summary['ì›”'].tolist()[::step]
    sns.lineplot(data=monthly_summary, x='ì›”', y='ë¦¬ë·° ìˆ˜', ax=axes[0], marker='o')
    axes[0].set_xticks(ticks)
    axes[0].tick_params(axis='x', rotation=45)
    axes[0].set_title('ì›”ë³„ ë¦¬ë·° ìˆ˜')

    sns.lineplot(data=monthly_summary, x='ì›”', y='ë³„ì ', ax=axes[1], marker='o', color='orange')
    axes[1].set_xticks(ticks)
    axes[1].tick_params(axis='x', rotation=45)
    axes[1].set_title('ì›”ë³„ í‰ê·  ë³„ì ')
    st.pyplot(fig)


    # í…ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
    texts = df[df['ë³„ì '] <= 3]['ë¦¬ë·° ë‚´ìš©'].dropna().astype(str).tolist()

    
    # ë¶€ì • í‚¤ì›Œë“œ ë° ê°€ì¤‘ì¹˜
    negative_seeds = [
        'ë¶ˆí¸', 'ë³„ë¡œ', 'ê³ ì¥', 'ëŠë¦¼', 'ì‹¤ë§', 'ì§œì¦', 'í™”ë‚¨', 'ë¶ˆë§Œ',
        'ì•„ì‰¬ì›€', 'ë¶€ì¡±', 'ë¶ˆì¾Œ', 'ì§€ë£¨', 'ë¶ˆì¹œì ˆ', 'ë³µì¡', 'í—·ê°ˆë¦¼',
        'ì•½í•¨', 'ë¬´ê±°ì›€', 'ë¶ˆëŸ‰'
    ]
    weight_map = {word: 2 for word in negative_seeds}

    st.spinner("âœ… í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ì •ê·œí™” ì¤‘ì…ë‹ˆë‹¤...")
    normalized_texts = normalize_texts(texts)

    # 2-3ê·¸ë¨ ì¶”ì¶œ
    vectorizer = CountVectorizer(ngram_range=(2, 3), min_df=1)
    X = vectorizer.fit_transform(normalized_texts)
    ngram_freq = pd.Series(X.toarray().sum(axis=0), index=vectorizer.get_feature_names_out()).sort_values(ascending=False)

    if not ngram_freq.empty:
        max_freq = ngram_freq.max()
        colors = ['orange' if v == max_freq else 'skyblue' for v in ngram_freq.values[:30]]

        # ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(12, 8))
        sns.barplot(x=ngram_freq.values[:30], y=ngram_freq.index[:30], palette=colors, ax=ax)
        ax.set_title('2-3ê·¸ë¨ ë¹ˆë„ ë¶„ì„ (ì •ê·œí™” ë° ì „ì²˜ë¦¬ ì ìš©)', fontsize=16)
        ax.set_xlabel('ë¹ˆë„', fontsize=12)
        ax.set_ylabel('2-3ê·¸ë¨ ë‹¨ì–´', fontsize=12)
        st.pyplot(fig)

        # # í…Œì´ë¸”ë¡œë„ ì¶œë ¥
        # st.subheader("ğŸ“‹ ìƒìœ„ 2-3ê·¸ë¨ ë¹ˆë„í‘œ")
        # st.dataframe(ngram_freq.head(30).reset_index().rename(columns={"index": "2-3ê·¸ë¨", 0: "ë¹ˆë„"}))
    else:
        st.warning("âš ï¸ ì˜ë¯¸ ìˆëŠ” 2-3ê·¸ë¨ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤. ë¦¬ë·° ìˆ˜ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜ ë¬¸ì¥ì„ ë” ì •ê·œí™”í•˜ì„¸ìš”.")



# ==========================================================================================================
    pos = extract_context(df['ë¦¬ë·° ë‚´ìš©'], POS_TARGETS)
    neg = extract_context(df['ë¦¬ë·° ë‚´ìš©'], NEG_TARGETS)

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ê¸ì • í‚¤ì›Œë“œ TOP 20")
        st.dataframe(pd.DataFrame(pos.most_common(20), columns=["ë‹¨ì–´", "ë¹ˆë„"]))
        buf = generate_wordcloud_image(pos, "Blues")
        if buf: st.image(buf, use_container_width=True)
    with col2:
        st.subheader("ë¶€ì • í‚¤ì›Œë“œ TOP 20")
        st.dataframe(pd.DataFrame(neg.most_common(20), columns=["ë‹¨ì–´", "ë¹ˆë„"]))
        buf = generate_wordcloud_image(neg, "Reds")
        if buf: st.image(buf, use_container_width=True)
        
    st.markdown("---")
    
    
    # st.markdown("### TOP20 ê¸ì • í‚¤ì›Œë“œë³„ ìƒí’ˆ ì¢…ë¥˜ ë¶„í¬")
    # df_plot = prepare_log_nom_treemap_data(tag_grouped_dfs, POS_TARGETS, STOPWORDS)
    # show_treemap(df_plot, "ë¡œê·¸ì •ê·œí™”_ë¹ˆë„", "ì •ê·œí™”ëœ ê¸ì • í‚¤ì›Œë“œ")

    # st.markdown("### TOP20 ë¶€ì • í‚¤ì›Œë“œë³„ ìƒí’ˆ ì¢…ë¥˜ ë¶„í¬")
    # df_plot = prepare_log_nom_treemap_data(tag_grouped_dfs, NEG_TARGETS, STOPWORDS)
    # show_treemap(df_plot, "ë¡œê·¸ì •ê·œí™”_ë¹ˆë„", "ì •ê·œí™”ëœ ë¶€ì • í‚¤ì›Œë“œ")
